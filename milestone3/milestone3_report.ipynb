{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Milestone 3: Traditional statistical and machine learning methods, due Wednesday, April 19, 2017\n",
    "\n",
    "Think about how you would address the genre prediction problem with traditional statistical or machine learning methods. This includes everything you learned about modeling in this course before the deep learning part. Implement your ideas and compare different classifiers. Report your results and discuss what challenges you faced and how you overcame them. What works and what does not? If there are parts that do not work as expected, make sure to discuss briefly what you think is the cause and how you would address this if you would have more time and resources. \n",
    "\n",
    "You do not necessarily need to use the movie posters for this step, but even without a background in computer vision, there are very simple features you can extract from the posters to help guide a traditional machine learning model. Think about the PCA lecture for example, or how to use clustering to extract color information. In addition to considering the movie posters it would be worthwhile to have a look at the metadata that IMDb provides. \n",
    "\n",
    "You could use Spark and the [ML library](https://spark.apache.org/docs/latest/ml-features.html#word2vec) to build your model features from the data. This may be especially beneficial if you use additional data, e.g., in text form.\n",
    "\n",
    "You also need to think about how you are going to evaluate your classifier. Which metrics or scores will you report to show how good the performance is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Detailed description and implementation of two different models\n",
    "\n",
    "### Baseline models: \n",
    "We will use One vs Rest Classification with various sets of movie data: \n",
    "  - independently training one binary classifier for each label.\n",
    "  - predict all labels for a new sample for which the respective classifiers predict a positive result\n",
    "         \n",
    "We will use Support Vector Machines and Random Forest Classifiers for the OneVsRestClassification. \n",
    "\n",
    "**Model 1: SVM/RF on the IMDB/TDMB movie metadata**\n",
    "\n",
    "Movie features including release data, rating, stunts etc will be used as the input to the OneVsRestClassifier with both SVM (linear and radial kernels) and RF. The parameters of SVM and RF will be tuned using cross validation. \n",
    "\n",
    "We will also experiment with using a multi layer perceptron with 1-2 hidden layers\n",
    "   - output layer has n sigmoid activation units where n is the number of unique genres\n",
    "   - output is a binary vector with 1s indicating the movie has the movie genre given by that position in the label vector\n",
    "\n",
    "\n",
    "**Model 2: RF on the IMDB keyword data**\n",
    "\n",
    "We will first create a one hot encoded matrix for all the unique keywords (~12,000) and use a separate RF classifier for each genre. We can then use the RF feature importances to determine which keywords are most relevant in classifying each genre. This can subsequently be used as a dimensionality reduction technique - we can select the top 10 keywords from the feature importances for each genre and add them to the movie metadata. \n",
    "\n",
    "In addition we can also use a OneVsRestClassifier on the one hot encoded keyword vectors to predict a multilabel output.\n",
    "\n",
    "**Model 3: PCA on the IMDB movie posters**\n",
    "\n",
    "We also plan to use the movie posters in a classification model. We will first apply dimensionality reduction using PCA, retaining the components which contribute to 90% of the variance. \n",
    "\n",
    "The training and testing data can then be projected onto the top principal components and this can be used as the input into a OneVsRestClassifier using SVM/RF. \n",
    "\n",
    "\n",
    "## Description of your performance metrics\n",
    "\n",
    "We will use three metrics to evaluate the performance of our classifiers:\n",
    "\n",
    " - Hamming loss: the fraction of the wrong labels to the total number of labels\n",
    " - Percent at least one match: proportion of movies for which at least one genre was predicted correctly\n",
    " - Percent exact match: percentage of movies that have all their genres correctly predicted\n",
    "\n",
    "## Careful performance evaluations for both models\n",
    "\n",
    "| Model | hamming loss | percent exact match | percent at least one match |\n",
    "|-----------|----|----|--------|\n",
    "| Tuned Radial SVM on movie metadata         | 0.082  |  63.05%  |    88.8%    |\n",
    "| Tuned RF on movie metadata         | 0.088  | 61.5%  | 95.3%     |\n",
    "| ANN on movie metadata         | 0.248  | 13.1% | 96.8%    |\n",
    "| RF on keywords        | 0.194  |  27.5%  |   75.2%.     |\n",
    "| PCA on posters + untuned SVM         | 0.212  | 13.4%  | 100%     |\n",
    "\n",
    "## Discussion of the differences between the models, their strengths, weaknesses, etc.\n",
    "\n",
    "Comparing the metrics from the different models the following observations can be made:\n",
    "- Tuned Radial SVM has the lowest Hamming loss and highest percentage of exact matches. Both these metrics indicate low error rate. \n",
    "- Tuned RF also has similar performace to the radial SVM with higher percent of at least one label matching without much decrease in the percent exact match. \n",
    "- Untuned ANN on the movie metadata has high percent of at least one label matching however it has very low percent exact match and the highest hamming loss out of all the models. \n",
    "- RF on the keywords has a higher hamming loss indicating higher fraction of mislabelling and also has low percent exact match. \n",
    "- PCA overpredicts some of the genres, result in 100% of a least one label matching but a very low number of exact matches ( this could also be due to the smaller data set used for PCA due to computation limitations). \n",
    "\n",
    "This analysis indicates that the tuned SVM and RF on the movie metadata are the best performing models with the lowest error rate and highest percentage of exact mathces. Further feature engineering could help to improve performance. \n",
    "\n",
    "## Visualizations of the metrics for performance evaluation\n",
    "\n",
    "Visualiations of performance are provided in each of the separate notebooks for each model. \n",
    "\n",
    "\n",
    "## Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "\n",
    "We plan to improve on the performances of the models in the following ways:\n",
    "\n",
    "- We will select the top 10 keywords from each genre based on the RF feature extraction and add it to the TMDB metadata. We will then redo the analysis for Model 1 using SVM/RF in a OneVsRestClassifier and ANN.  We will investigate methods of tuning the ANN parameters and optimise performance. \n",
    "- We will also look into further feature engineering using information about directors by performing a similar RF analysis and determining the top directors for each genre. As directors are often closely associated with a genre this could be strong predictor. \n",
    "\n",
    "- We will consider running the PCA model on a GPU with the full dataset to observe whether performance of a OneVsRestClassifier improves\n",
    "- We will implement CNN models on the movie data to predict labels including training a small CNN + MLP network from scratch, using a pretrained model and fine tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
