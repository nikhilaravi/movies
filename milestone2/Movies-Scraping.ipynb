{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Scraping from TMDB and IMDB\n",
    "## Team MovieGnat\n",
    "\n",
    "**Here are the steps to take:**\n",
    "\n",
    "1. Run Part 1 to grab all movies and keywords from TMDB API and put them into your CSV file titled: *tmdb-movies-1-to-400.csv*, *tmdb-movies-401-to-800.csv*, etc.\n",
    "\n",
    "2. Run Part 2 to grab all the IMDB ids from the TMDB ids provided as the .csv file you generated in Step 1. Write the output into another CSV titled: *imdb-ids-1-to-400.csv*, *imdb-ids-401-to-800.csv*, etc.\n",
    "\n",
    "3. Run Part 3 to grab features from IMDB API given IMDB ids provided as the .csv file generated in Step 2. Write the output into another CSV titles: *imdb-features-1-to-400.csv*, *imdb-features-401-to-800.csv*, etc.\n",
    "\n",
    "4. Merge all the CSV files and output to a full-movies-1-to-400.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 1:  STANDALONE TO GRAB ALL MOVIES AND KEYWORDS\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "#########################################################\n",
    "'''\n",
    "BASE STUFF THAT IS ALSO DEFINED ON TOP\n",
    "'''\n",
    "def requestResults(url):\n",
    "    r = requests.get(BASE_URL + url + \"&api_key=\" + API_KEY)\n",
    "    return r.json()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://api.themoviedb.org/3/\"\n",
    "API_KEY = \"9767d17413ec9d9729c2cca238df02da\"\n",
    "GENRE_MAP = {}\n",
    "for g in requestResults(\"genre/movie/list?x=1\")[u'genres']:\n",
    "    GENRE_MAP[g['id']] = g['name']\n",
    "    \n",
    "#########################################################\n",
    "\n",
    "\n",
    "def _getKeywordsStringById(movie_id):\n",
    "    \n",
    "    keywords_dict = requestResults(\"movie/\" + str(movie_id) + \"/keywords?language=en-US\")\n",
    "    if u'keywords' not in keywords_dict:\n",
    "        return ''\n",
    "    keywords_dict = keywords_dict[u'keywords']\n",
    "    kstring = ''\n",
    "    for k in keywords_dict:\n",
    "        kstring += k[u'name'] + ','\n",
    "    return str(kstring.encode('utf-8').strip())[:-1]\n",
    "\n",
    "def _tidyRow(m, keywords):\n",
    "    # Makes sure the row of movie is well-formatted\n",
    "    output = {}\n",
    "    for k in m:\n",
    "        typem = type(m[k])\n",
    "        k = str(k)\n",
    "        if typem == str or typem == unicode:\n",
    "            output[k] = m[k].encode('utf-8').strip()\n",
    "        else:\n",
    "            output[k] = m[k]\n",
    "    output['keywords'] = keywords\n",
    "    return output\n",
    "\n",
    "def downloadMoviesToCSV(start_page, increment, filename):\n",
    "    genre_count = {}\n",
    "    \n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'genre_ids', 'poster_path', 'title', 'overview', 'release_date', \n",
    "                      'popularity', 'original_title', 'backdrop_path', 'keywords', \n",
    "                     'vote_count', 'video', 'adult', 'vote_average', 'original_language']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Get keywords for movies\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # TMDB limits 4 requests per second\n",
    "        hit = 3 # Once hit reaches 0, call timer and reset hit to 3\n",
    "        \n",
    "        for p in range(start_page,start_page+increment): \n",
    "            results_p = requestResults(\"discover/movie?sort_by=popularity.desc&page=\" + str(p))[u'results']\n",
    "            hit -= 1\n",
    "            if hit <= 0:\n",
    "                hit = 3\n",
    "                time.sleep(1)\n",
    "\n",
    "            # Write to CSV\n",
    "            for m in results_p:\n",
    "                mid = m[u'id']\n",
    "                keywords = _getKeywordsStringById(mid)\n",
    "                hit -= 1\n",
    "                if hit <= 0:\n",
    "                    hit = 3\n",
    "                    time.sleep(1)\n",
    "                \n",
    "                row = _tidyRow(m, keywords)\n",
    "                writer.writerow(row)\n",
    "            print('%d pages done' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c9041d3c53ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Run Part 1: REMEMBER TO CHANGE start_page to your start page, don't have to change increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloadMoviesToCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tmdb-movies-1001-to-1200.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-329236626605>\u001b[0m in \u001b[0;36mdownloadMoviesToCSV\u001b[0;34m(start_page, increment, filename)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_page\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_page\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresults_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequestResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"discover/movie?sort_by=popularity.desc&page=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mhit\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'results'"
     ]
    }
   ],
   "source": [
    "### Run Part 1: REMEMBER TO CHANGE start_page to your start page, don't have to change increment\n",
    "downloadMoviesToCSV(start_page=1001, increment=200, filename='tmdb-movies-1001-to-1200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART 2: STANDALONE THAT TAKES IN .CSV FILE AND GETS ALL IMDB IDS in a separate file\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "#########################################################\n",
    "'''\n",
    "BASE STUFF THAT IS ALSO DEFINED ON TOP\n",
    "'''\n",
    "def requestResults(url):\n",
    "    r = requests.get(BASE_URL + url + \"&api_key=\" + API_KEY)\n",
    "    return r.json()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://api.themoviedb.org/3/\"\n",
    "API_KEY = \"9767d17413ec9d9729c2cca238df02da\"\n",
    "GENRE_MAP = {}\n",
    "for g in requestResults(\"genre/movie/list?x=1\")[u'genres']:\n",
    "    GENRE_MAP[g['id']] = g['name']\n",
    "    \n",
    "#########################################################\n",
    "\n",
    "def downloadIMDBIds(input_filename, output_filename):\n",
    "    df = pd.read_csv(input_filename)\n",
    "\n",
    "    with open(output_filename, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'imdb_id']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # TMDB limits 4 requests per second\n",
    "        hit = 3 # Once hit reaches 0, call timer and reset hit to 3\n",
    "\n",
    "        count = 0\n",
    "        for tmid in df['id']:\n",
    "            count += 1\n",
    "            results = requestResults('movie/' + str(tmid) + '?x=1')\n",
    "            if u'imdb_id' not in results or results[u'imdb_id'] is None:\n",
    "                continue\n",
    "            imid = results[u'imdb_id'].strip('tt')\n",
    "            row = {'id': tmid, 'imdb_id': imid}\n",
    "            writer.writerow(row)\n",
    "            hit -= 1\n",
    "            if hit <= 0:\n",
    "                hit = 3\n",
    "                time.sleep(1)\n",
    "            if count % 200 == 0:\n",
    "                print 'done with %d movies' % count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 200 movies\n",
      "done with 400 movies\n",
      "done with 600 movies\n",
      "done with 800 movies\n",
      "done with 1000 movies\n",
      "done with 1200 movies\n",
      "done with 1400 movies\n",
      "done with 1600 movies\n",
      "done with 1800 movies\n",
      "done with 2000 movies\n",
      "done with 2200 movies\n",
      "done with 2400 movies\n",
      "done with 2600 movies\n",
      "done with 2800 movies\n",
      "done with 3000 movies\n",
      "done with 3200 movies\n",
      "done with 3400 movies\n",
      "done with 3600 movies\n",
      "done with 3800 movies\n",
      "done with 4000 movies\n"
     ]
    }
   ],
   "source": [
    "### Run Part 2: Get imdb ids from tmdb ids input csv file\n",
    "downloadIMDBIds(input_filename='tmdb-movies-1001-to-1200.csv', output_filename='imdb-ids-1001-to-1200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 3: STANDALONE THAT TAKES IN IMDB IDs and gets IMDB features\n",
    "'''\n",
    "Make sure you have IMDB installed.\n",
    "- Go to: http://imdbpy.sourceforge.net/\n",
    "- Download and unzip, then cd into it and make sure there is a setup.py file\n",
    "- Run python setup.py install\n",
    "- You're done! It's globally installed.\n",
    "'''\n",
    "import imdb\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def getIMDBFeatures(input_filename, output_filename, start, increment):\n",
    "\n",
    "    # Note: This cannot be terminated via the stop button (interrupt the kernel), \n",
    "    # got to restart the kernel (use rewind button) :(\n",
    "    \n",
    "    ia = imdb.IMDb()\n",
    "    df = pd.read_csv(input_filename)\n",
    "    # Download increment movies at a time\n",
    "    df = df[start:start+increment]\n",
    "    \n",
    "    imids = np.array(df['imdb_id'])\n",
    "\n",
    "    with open(output_filename + '-' + str(start), 'w') as csvfile:\n",
    "        # Grab these features from IMDB\n",
    "        fieldnames = ['imdb_id', 'director', 'imdb_votes', 'certificate', 'num_stunts', 'num_fx']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        count = 0\n",
    "        for imid in imids:\n",
    "            count += 1\n",
    "            # Tries twice because sometimes it fails\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    movie = ia.get_movie(str(int(imid)))\n",
    "                    director = movie['director'][0]\n",
    "                    imdb_votes = movie['votes']\n",
    "                    certificate = movie['certificates'][-2].split(':')[1]\n",
    "                    num_stunts = len(movie['stunt performer'])\n",
    "                    num_fx = len(movie['special effects department'])\n",
    "                    row = {'imdb_id': imid, 'director': director, 'imdb_votes': imdb_votes, 'certificate': certificate, \n",
    "                          'num_stunts': num_stunts, 'num_fx': num_fx}\n",
    "                    writer.writerow(row)\n",
    "                    break\n",
    "                except:    \n",
    "                    pass\n",
    "            if count % 100 == 0:\n",
    "                print 'Done with %d movies' % count\n",
    "    print 'Done with page %d' % ((start%increment) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with 500 movies\n",
      "Done with page 1\n",
      "Done with 100 movies\n",
      "Done with 200 movies\n",
      "Done with 300 movies\n",
      "Done with 400 movies\n",
      "Done with page 1\n"
     ]
    }
   ],
   "source": [
    "### Run Part 3: Get imdb features from imdb ids\n",
    "\n",
    "# NOTE: This downloads 500 movies at a time and stores each in a different file.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('imdb-ids-1001-to-1200.csv')\n",
    "N = df.shape[0]\n",
    "increment = 500 # Work on 500 movies at a time\n",
    "end_page = N/increment\n",
    "\n",
    "##############################################################\n",
    "# NOTE: If you are done with page 2 (1000 movies), then change this to 2 the next time you start\n",
    "start_page = 0\n",
    "##############################################################\n",
    "\n",
    "starts = [] \n",
    "for i in range(start_page,end_page): # default starts: [500,1000,1500,2000,2500,..,7500]\n",
    "    starts.append((i+1)*increment)\n",
    "\n",
    "for start in starts: \n",
    "    getIMDBFeatures(input_filename='imdb-ids-1001-to-1200.csv', output_filename='imdb-features-1001-to-1200.csv', \n",
    "                    start=start, increment=increment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PART 4: Merge all and output CSV file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# NOTE: Change to your filepath and start and end movie\n",
    "prefix_filepath = 'leo-data/'\n",
    "start = 1\n",
    "end = 400\n",
    "\n",
    "# Merge all imdb features into one\n",
    "imdb_features = pd.read_csv(prefix_filepath + 'imdb-features-'+str(start)+'-to-'+str(end)+'.csv-500')\n",
    "for p in range(2,16):\n",
    "    imdb_features_ = pd.read_csv(prefix_filepath + 'imdb-features-'+str(start)+'-to-'+str(end)+'.csv-' + str(p*500))\n",
    "    imdb_features = imdb_features.append(imdb_features_)\n",
    "\n",
    "# Merge imdb ids with imdb features\n",
    "imdb_ids = pd.read_csv(prefix_filepath + 'imdb-ids-'+str(start)+'-to-'+str(end)+'.csv')\n",
    "imdb_ids = imdb_ids.rename(index=str, columns={\"id\": \"tmdb_id\"})\n",
    "imdb_merged = imdb_ids.merge(imdb_features, how='outer', left_on='imdb_id', right_on='imdb_id')\n",
    "imdb_merged = imdb_merged.dropna()\n",
    "\n",
    "# Merge tmdb with imdb_merge\n",
    "tmdb_movies = pd.read_csv(prefix_filepath + 'tmdb-movies-'+str(start)+'-to-'+str(end)+'.csv')\n",
    "tmdb_movies = tmdb_movies.rename(index=str, columns={\"id\": \"tmdb_id\"})\n",
    "full_movies = tmdb_movies.merge(imdb_merged, how='outer', left_on='tmdb_id', right_on='tmdb_id')\n",
    "full_movies = full_movies.dropna()\n",
    "\n",
    "# Output this to CSV of full movies\n",
    "full_movies.to_csv('full-movies-'+str(start)+'-to-'+str(end)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>keywords</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>director</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>certificate</th>\n",
       "      <th>num_stunts</th>\n",
       "      <th>num_fx</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[28, 53, 878, 9648]</td>\n",
       "      <td>/h3lpltSn7Rj1eYTPQO1lYGdw4Bz.jpg</td>\n",
       "      <td>Minority Report</td>\n",
       "      <td>4.023489</td>\n",
       "      <td>self-fulfilling prophecy,evidence,hologram,dys...</td>\n",
       "      <td>2035</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>418905.0</td>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[12, 53, 878]</td>\n",
       "      <td>/xXMM9KY2eq1SDOQif9zO91YOBA8.jpg</td>\n",
       "      <td>War of the Worlds</td>\n",
       "      <td>4.022906</td>\n",
       "      <td>post traumatic stress  disorder,new jersey,air...</td>\n",
       "      <td>1690</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>349381.0</td>\n",
       "      <td>12A</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[878, 18]</td>\n",
       "      <td>/mABOVIUl5lB0WF4HG28rfamgxG1.jpg</td>\n",
       "      <td>Close Encounters of the Third Kind</td>\n",
       "      <td>4.018199</td>\n",
       "      <td>indiana,obsession,extraterrestrial technology,...</td>\n",
       "      <td>849</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>146265.0</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 18, 53]</td>\n",
       "      <td>/c6Nu7UjhGCQtV16WXabqOQfikK6.jpg</td>\n",
       "      <td>127 Hours</td>\n",
       "      <td>4.017993</td>\n",
       "      <td>mountains,despair,adventure,utah,alone,canyon,...</td>\n",
       "      <td>2067</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Danny Boyle</td>\n",
       "      <td>292099.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27]</td>\n",
       "      <td>/vHTXN00kJktCbSLV50Vbk9siNiX.jpg</td>\n",
       "      <td>Ouija</td>\n",
       "      <td>4.014788</td>\n",
       "      <td>death of a friend,swimming pool,ouija,ouija bo...</td>\n",
       "      <td>726</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Stiles White</td>\n",
       "      <td>37043.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genre_ids                       poster_path  \\\n",
       "0  [28, 53, 878, 9648]  /h3lpltSn7Rj1eYTPQO1lYGdw4Bz.jpg   \n",
       "1        [12, 53, 878]  /xXMM9KY2eq1SDOQif9zO91YOBA8.jpg   \n",
       "2            [878, 18]  /mABOVIUl5lB0WF4HG28rfamgxG1.jpg   \n",
       "3         [12, 18, 53]  /c6Nu7UjhGCQtV16WXabqOQfikK6.jpg   \n",
       "4                 [27]  /vHTXN00kJktCbSLV50Vbk9siNiX.jpg   \n",
       "\n",
       "                                title  popularity  \\\n",
       "0                     Minority Report    4.023489   \n",
       "1                   War of the Worlds    4.022906   \n",
       "2  Close Encounters of the Third Kind    4.018199   \n",
       "3                           127 Hours    4.017993   \n",
       "4                               Ouija    4.014788   \n",
       "\n",
       "                                            keywords  vote_count  \\\n",
       "0  self-fulfilling prophecy,evidence,hologram,dys...        2035   \n",
       "1  post traumatic stress  disorder,new jersey,air...        1690   \n",
       "2  indiana,obsession,extraterrestrial technology,...         849   \n",
       "3  mountains,despair,adventure,utah,alone,canyon,...        2067   \n",
       "4  death of a friend,swimming pool,ouija,ouija bo...         726   \n",
       "\n",
       "   vote_average          director  imdb_votes certificate  num_stunts  num_fx  \\\n",
       "0           7.0  Steven Spielberg    418905.0          12        88.0    49.0   \n",
       "1           6.1  Steven Spielberg    349381.0         12A        94.0    90.0   \n",
       "2           7.2  Steven Spielberg    146265.0       TV-MA        10.0     8.0   \n",
       "3           6.9       Danny Boyle    292099.0          15        11.0     6.0   \n",
       "4           4.9      Stiles White     37043.0          15        20.0     4.0   \n",
       "\n",
       "   year  month  \n",
       "0  2002      6  \n",
       "1  2005      6  \n",
       "2  1977     11  \n",
       "3  2010     11  \n",
       "4  2014     10  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PART 5: Clean up columns to choose the right ones for Milestone 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('full-movies-1-to-400.csv')\n",
    "\n",
    "# Choose only columns we need\n",
    "cols = ['genre_ids', 'poster_path', 'title', 'release_date', 'popularity', 'keywords', 'vote_count',\n",
    "       'vote_average', 'director', 'imdb_votes', 'certificate', 'num_stunts', 'num_fx']\n",
    "df = df[cols]\n",
    "\n",
    "# Break down release date into month and year\n",
    "datesplit = df['release_date'].str.split('-')\n",
    "years = [int(d[0]) for d in datesplit]\n",
    "months = [int(d[1]) for d in datesplit]\n",
    "df['year'] = years\n",
    "df['month'] = months\n",
    "del df['release_date']\n",
    "\n",
    "# TODO: Choose top 20 keywords / clustering, etc.\n",
    "# TODO: Apply one hot encoding to multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
