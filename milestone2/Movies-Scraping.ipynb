{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Scraping from TMDB and IMDB\n",
    "## Team MovieGnat\n",
    "\n",
    "**Here are the steps to take:**\n",
    "\n",
    "1. Run Part 1 to grab all movies and keywords from TMDB API and put them into your CSV file titled: *tmdb-movies-1-to-400.csv*, *tmdb-movies-401-to-800.csv*, etc.\n",
    "\n",
    "2. Run Part 2 to grab all the IMDB ids from the TMDB ids provided as the .csv file you generated in Step 1. Write the output into another CSV titled: *imdb-ids-1-to-400.csv*, *imdb-ids-401-to-800.csv*, etc.\n",
    "\n",
    "3. Run Part 3 to grab features from IMDB API given IMDB ids provided as the .csv file generated in Step 2. Write the output into another CSV titles: *imdb-features-1-to-400.csv*, *imdb-features-401-to-800.csv*, etc.\n",
    "\n",
    "4. (Not yet done) We will have to map the IMDB features back to the part 1 dataset of TMDB features based on ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 1:  STANDALONE TO GRAB ALL MOVIES AND KEYWORDS\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "#########################################################\n",
    "'''\n",
    "BASE STUFF THAT IS ALSO DEFINED ON TOP\n",
    "'''\n",
    "def requestResults(url):\n",
    "    r = requests.get(BASE_URL + url + \"&api_key=\" + API_KEY)\n",
    "    return r.json()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://api.themoviedb.org/3/\"\n",
    "API_KEY = \"9767d17413ec9d9729c2cca238df02da\"\n",
    "GENRE_MAP = {}\n",
    "for g in requestResults(\"genre/movie/list?x=1\")[u'genres']:\n",
    "    GENRE_MAP[g['id']] = g['name']\n",
    "    \n",
    "#########################################################\n",
    "\n",
    "\n",
    "def _getKeywordsStringById(movie_id):\n",
    "    \n",
    "    keywords_dict = requestResults(\"movie/\" + str(movie_id) + \"/keywords?language=en-US\")\n",
    "    if u'keywords' not in keywords_dict:\n",
    "        return ''\n",
    "    keywords_dict = keywords_dict[u'keywords']\n",
    "    kstring = ''\n",
    "    for k in keywords_dict:\n",
    "        kstring += k[u'name'] + ','\n",
    "    return str(kstring.encode('utf-8').strip())[:-1]\n",
    "\n",
    "def _tidyRow(m, keywords):\n",
    "    # Makes sure the row of movie is well-formatted\n",
    "    output = {}\n",
    "    for k in m:\n",
    "        typem = type(m[k])\n",
    "        k = str(k)\n",
    "        if typem == str or typem == unicode:\n",
    "            output[k] = m[k].encode('utf-8').strip()\n",
    "        else:\n",
    "            output[k] = m[k]\n",
    "    output['keywords'] = keywords\n",
    "    return output\n",
    "\n",
    "def downloadMoviesToCSV(start_page, increment, filename):\n",
    "    genre_count = {}\n",
    "    \n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'genre_ids', 'poster_path', 'title', 'overview', 'release_date', \n",
    "                      'popularity', 'original_title', 'backdrop_path', 'keywords', \n",
    "                     'vote_count', 'video', 'adult', 'vote_average', 'original_language']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Get keywords for movies\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # TMDB limits 4 requests per second\n",
    "        hit = 3 # Once hit reaches 0, call timer and reset hit to 3\n",
    "        \n",
    "        for p in range(start_page,start_page+increment): \n",
    "            results_p = requestResults(\"discover/movie?sort_by=popularity.desc&page=\" + str(p))[u'results']\n",
    "            hit -= 1\n",
    "            if hit <= 0:\n",
    "                hit = 3\n",
    "                time.sleep(1)\n",
    "\n",
    "            # Write to CSV\n",
    "            for m in results_p:\n",
    "                mid = m[u'id']\n",
    "                keywords = _getKeywordsStringById(mid)\n",
    "                hit -= 1\n",
    "                if hit <= 0:\n",
    "                    hit = 3\n",
    "                    time.sleep(1)\n",
    "                \n",
    "                row = _tidyRow(m, keywords)\n",
    "                writer.writerow(row)\n",
    "            print('%d pages done' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 pages done\n"
     ]
    }
   ],
   "source": [
    "### Run Part 1: REMEMBER TO CHANGE start_page to your start page, don't have to change increment\n",
    "downloadMoviesToCSV(start_page=801, increment=400, filename='tmdb-movies-801-to-1200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART 2: STANDALONE THAT TAKES IN .CSV FILE AND GETS ALL IMDB IDS in a separate file\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "#########################################################\n",
    "'''\n",
    "BASE STUFF THAT IS ALSO DEFINED ON TOP\n",
    "'''\n",
    "def requestResults(url):\n",
    "    r = requests.get(BASE_URL + url + \"&api_key=\" + API_KEY)\n",
    "    return r.json()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://api.themoviedb.org/3/\"\n",
    "API_KEY = \"9767d17413ec9d9729c2cca238df02da\"\n",
    "GENRE_MAP = {}\n",
    "for g in requestResults(\"genre/movie/list?x=1\")[u'genres']:\n",
    "    GENRE_MAP[g['id']] = g['name']\n",
    "    \n",
    "#########################################################\n",
    "\n",
    "def downloadIMDBIds(input_filename, output_filename):\n",
    "    df = pd.read_csv(input_filename)\n",
    "\n",
    "    with open(output_filename, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'imdb_id']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # TMDB limits 4 requests per second\n",
    "        hit = 3 # Once hit reaches 0, call timer and reset hit to 3\n",
    "\n",
    "        count = 0\n",
    "        for tmid in df['id']:\n",
    "            count += 1\n",
    "            results = requestResults('movie/' + str(tmid) + '?x=1')\n",
    "            if u'imdb_id' not in results or results[u'imdb_id'] is None:\n",
    "                continue\n",
    "            imid = results[u'imdb_id'].strip('tt')\n",
    "            row = {'id': tmid, 'imdb_id': imid}\n",
    "            writer.writerow(row)\n",
    "            hit -= 1\n",
    "            if hit <= 0:\n",
    "                hit = 3\n",
    "                time.sleep(1)\n",
    "            if count % 200 == 0:\n",
    "                print 'done with %d movies' % count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run Part 2: Get imdb ids from tmdb ids input csv file\n",
    "downloadIMDBIds(input_filename='tmdb-movies-801-to-1200.csv', output_filename='imdb-ids-801-to-1200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 3: STANDALONE THAT TAKES IN IMDB IDs and gets IMDB features\n",
    "'''\n",
    "Make sure you have IMDB installed.\n",
    "- Go to: http://imdbpy.sourceforge.net/\n",
    "- Download and unzip, then cd into it and make sure there is a setup.py file\n",
    "- Run python setup.py install\n",
    "- You're done! It's globally installed.\n",
    "'''\n",
    "import imdb\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def getIMDBFeatures(input_filename, output_filename, start, increment):\n",
    "\n",
    "    # Note: This cannot be terminated via the stop button (interrupt the kernel), \n",
    "    # got to restart the kernel (use rewind button) :(\n",
    "    \n",
    "    ia = imdb.IMDb()\n",
    "    df = pd.read_csv(input_filename)\n",
    "    # Download increment movies at a time\n",
    "    df = df[start:start+increment]\n",
    "    \n",
    "    imids = np.array(df['imdb_id'])\n",
    "\n",
    "    with open(output_filename + '-' + str(start), 'w') as csvfile:\n",
    "        # Grab these features from IMDB\n",
    "        fieldnames = ['imdb_id', 'director', 'imdb_votes', 'certificate', 'num_stunts', 'num_fx']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        count = 0\n",
    "        for imid in imids:\n",
    "            count += 1\n",
    "            # Tries twice because sometimes it fails\n",
    "            for i in range(2):\n",
    "                try:\n",
    "                    movie = ia.get_movie(str(int(imid)))\n",
    "                    director = movie['director'][0]\n",
    "                    imdb_votes = movie['votes']\n",
    "                    certificate = movie['certificates'][-2].split(':')[1]\n",
    "                    num_stunts = len(movie['stunt performer'])\n",
    "                    num_fx = len(movie['special effects department'])\n",
    "                    row = {'imdb_id': imid, 'director': director, 'imdb_votes': imdb_votes, 'certificate': certificate, \n",
    "                          'num_stunts': num_stunts, 'num_fx': num_fx}\n",
    "                    writer.writerow(row)\n",
    "                    break\n",
    "                except:    \n",
    "                    pass\n",
    "            if count % 100 == 0:\n",
    "                print 'Done with %d movies' % count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run Part 3: Get imdb features from imdb ids\n",
    "\n",
    "# NOTE: This downloads 500 movies at a time and stores it in a different file.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('imdb-ids-1-to-400.csv')\n",
    "N = df.shape[0]\n",
    "increment = 500 # Work on 500 movies at a time\n",
    "sections = N/increment\n",
    "\n",
    "# If you stop halfway change the starts array to: [2000,2500,..,7500] (this is when you are done with 1500 movies)\n",
    "starts = [] \n",
    "for i in range(sections): # default starts: [500,1000,1500,2000,2500,..,7500]\n",
    "    starts.append((i+1)*increment)\n",
    "\n",
    "# Output 500 movies in a file at a time\n",
    "for start in starts: \n",
    "    getIMDBFeatures(input_filename='imdb-ids-1-to-400.csv', output_filename='imdb-features-1-to-400.csv', \n",
    "                    start=start, increment=increment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
